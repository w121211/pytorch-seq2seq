{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "實驗：測試強化學習是否有效\n",
    "\n",
    "real_a -> fake_a'\n",
    "* Discrimintor: 區分為A or B，越接近B，分數越高\n",
    "* loss = lambda_a * NLL(fake_a, real_a) + lambda_b * Reward\n",
    "* 概念：一方面企圖讓G直接還原A，一方面用D來讓G生成像是B的sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chi/Work/pytorch-seq2seq\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "try:\n",
    "    pardir = os.path.realpath(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "except NameError:\n",
    "    pardir = os.path.split(os.getcwd())[0]\n",
    "if pardir not in sys.path:\n",
    "    sys.path.insert(0, pardir)\n",
    "\n",
    "from seq2seq.util.checkpoint import Checkpoint\n",
    "\n",
    "from ape import Constants, options\n",
    "from ape.dataset.lang8 import Lang8\n",
    "from ape.dataset.field import SentencePieceField\n",
    "from ape.model.discriminator import BinaryClassifierCNN\n",
    "from ape.model.transformer.Models import Transformer\n",
    "from ape import trainers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use CUDA? False\n",
      "Use CUDA? False\n",
      "Use CUDA? False\n",
      "Namespace(batch_size=1, beam_size=5, build_vocab_from='/Users/chi/Work/pytorch-seq2seq/./data/billion/billion.30m.model.vocab', cuda=False, d_inner_hid=1024, d_k=64, d_model=300, d_v=64, d_word_vec=512, device=-1, dropout=0.1, dropout_p=0.25, embed_dim=300, embs_share_weight=False, epoch=10, exp_dir='/Users/chi/Work/pytorch-seq2seq/./experiment/transformer-dualgan/use_billion', kernel_sizes=[2, 3, 4, 5, 6, 7], load_G_a_from='./experiment/transformer/lang8-err2cor/', load_G_b_from='./experiment/transformer/lang8-cor2err/', load_from=None, load_vocab_from='/Users/chi/Work/pytorch-seq2seq/./experiment/transformer/lang8-cor2err/vocab.pt', max_len=20, max_word_seq_len=50, n_best=1, n_epoch=5, n_head=8, n_layers=6, n_warmup_steps=4000, num_kernel=100, proj_share_weight=False)\n",
      "Namespace(batch_size=1, beam_size=5, build_vocab_from='/Users/chi/Work/pytorch-seq2seq/./data/billion/billion.30m.model.vocab', cuda=False, d_inner_hid=1024, d_k=64, d_model=300, d_v=64, d_word_vec=512, device=-1, dropout=0.1, dropout_p=0.25, embed_dim=300, embs_share_weight=False, epoch=10, exp_dir='/Users/chi/Work/pytorch-seq2seq/./experiment/transformer-dualgan/use_billion', kernel_sizes=[2, 3, 4, 5, 6, 7], load_G_a_from='./experiment/transformer/lang8-err2cor/', load_G_b_from='./experiment/transformer/lang8-cor2err/', load_from=None, load_vocab_from='/Users/chi/Work/pytorch-seq2seq/./experiment/transformer/lang8-cor2err/vocab.pt', max_len=20, max_word_seq_len=50, n_best=1, n_epoch=5, n_head=8, n_layers=6, n_warmup_steps=4000, num_kernel=100, proj_share_weight=False)\n",
      "Namespace(batch_size=1, beam_size=5, build_vocab_from='/Users/chi/Work/pytorch-seq2seq/./data/billion/billion.30m.model.vocab', cuda=False, d_inner_hid=1024, d_k=64, d_model=300, d_v=64, d_word_vec=512, device=-1, dropout=0.1, dropout_p=0.25, embed_dim=300, embs_share_weight=False, epoch=10, exp_dir='/Users/chi/Work/pytorch-seq2seq/./experiment/transformer-dualgan/use_billion', kernel_sizes=[2, 3, 4, 5, 6, 7], load_G_a_from='./experiment/transformer/lang8-err2cor/', load_G_b_from='./experiment/transformer/lang8-cor2err/', load_from=None, load_vocab_from='/Users/chi/Work/pytorch-seq2seq/./experiment/transformer/lang8-cor2err/vocab.pt', max_len=20, max_word_seq_len=50, n_best=1, n_epoch=5, n_head=8, n_layers=6, n_warmup_steps=4000, num_kernel=100, proj_share_weight=False)\n"
     ]
    }
   ],
   "source": [
    "LOG_FORMAT = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "opt = options.train_options(parser)\n",
    "opt = parser.parse_args(args=[])\n",
    "\n",
    "opt.cuda = torch.cuda.is_available()\n",
    "opt.device = None if opt.cuda else -1\n",
    "\n",
    "# 快速變更設定\n",
    "opt.exp_dir = './experiment/transformer-dualgan/use_billion'\n",
    "opt.load_vocab_from = './experiment/transformer/lang8-cor2err/vocab.pt'\n",
    "opt.build_vocab_from = './data/billion/billion.30m.model.vocab'\n",
    "\n",
    "opt.exp_dir = os.path.join(pardir, opt.exp_dir)\n",
    "opt.load_vocab_from = os.path.join(pardir, opt.load_vocab_from)\n",
    "opt.build_vocab_from = os.path.join(pardir, opt.build_vocab_from)\n",
    "\n",
    "# dataset params\n",
    "opt.max_len = 20\n",
    "\n",
    "# G params\n",
    "opt.load_G_a_from = './experiment/transformer/lang8-err2cor/'\n",
    "opt.load_G_b_from = './experiment/transformer/lang8-cor2err/'\n",
    "opt.d_model = 300  # 暫時需要\n",
    "\n",
    "# D params\n",
    "opt.embed_dim = opt.d_model\n",
    "opt.num_kernel = 100\n",
    "opt.kernel_sizes = [2, 3, 4, 5, 6, 7]\n",
    "opt.dropout_p = 0.25\n",
    "\n",
    "# train params\n",
    "opt.batch_size = 1\n",
    "opt.n_epoch = 5\n",
    "\n",
    "if not os.path.exists(opt.exp_dir):\n",
    "    os.makedirs(opt.exp_dir)\n",
    "\n",
    "logging.basicConfig(filename=opt.exp_dir + '/.log',\n",
    "                    format=LOG_FORMAT, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n",
    "\n",
    "logging.info('Use CUDA? ' + str(opt.cuda))\n",
    "logging.info(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load voab from /Users/chi/Work/pytorch-seq2seq/./experiment/transformer/lang8-cor2err/vocab.pt\n",
      "Load voab from /Users/chi/Work/pytorch-seq2seq/./experiment/transformer/lang8-cor2err/vocab.pt\n",
      "Load voab from /Users/chi/Work/pytorch-seq2seq/./experiment/transformer/lang8-cor2err/vocab.pt\n",
      "Vocab len: 8003\n",
      "Vocab len: 8003\n",
      "Vocab len: 8003\n"
     ]
    }
   ],
   "source": [
    "def len_filter(example):\n",
    "    return len(example.src) <= opt.max_len and len(example.tgt) <= opt.max_len\n",
    "\n",
    "EN = SentencePieceField(init_token=Constants.BOS_WORD,\n",
    "                        eos_token=Constants.EOS_WORD,\n",
    "                        batch_first=True)\n",
    "\n",
    "train = datasets.TranslationDataset(\n",
    "    path=os.path.join(pardir, './data/dualgan/train',),\n",
    "    exts=('.billion.sp', '.use.sp'), fields=[('src', EN), ('tgt', EN)],\n",
    "    filter_pred=len_filter)\n",
    "\n",
    "# 讀取 vocabulary（確保一致）\n",
    "try:\n",
    "    logging.info('Load voab from %s' % opt.load_vocab_from)\n",
    "    EN.load_vocab(opt.load_vocab_from)\n",
    "except FileNotFoundError:\n",
    "    EN.build_vocab_from(opt.build_vocab_from)\n",
    "    EN.save_vocab(opt.load_vocab_from)\n",
    "\n",
    "logging.info('Vocab len: %d' % len(EN.vocab))\n",
    "\n",
    "# 檢查Constants是否有誤\n",
    "assert EN.vocab.stoi[Constants.BOS_WORD] == Constants.BOS\n",
    "assert EN.vocab.stoi[Constants.EOS_WORD] == Constants.EOS\n",
    "assert EN.vocab.stoi[Constants.PAD_WORD] == Constants.PAD\n",
    "assert EN.vocab.stoi[Constants.UNK_WORD] == Constants.UNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_G' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-03d927c89de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_G_a_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mG_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_G_b_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mD_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mD_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_G' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "G_a = load_G(opt.load_G_a_from)\n",
    "G_b = load_G(opt.load_G_b_from)\n",
    "D_a = build_D(opt, EN)\n",
    "D_b = build_D(opt, EN)\n",
    "\n",
    "optim_G_a = optim.Adam(G_a.get_trainable_parameters(),\n",
    "                       betas=(0.9, 0.98), eps=1e-09)\n",
    "optim_G_b = optim.Adam(G_a.get_trainable_parameters(),\n",
    "                       betas=(0.9, 0.98), eps=1e-09)\n",
    "optim_D_a = torch.optim.Adam(D_a.parameters(), lr=1e-4)\n",
    "optim_D_b = torch.optim.Adam(D_b.parameters(), lr=1e-4)\n",
    "\n",
    "def get_criterion(vocab_size):\n",
    "    ''' With PAD token zero weight '''\n",
    "    weight = torch.ones(vocab_size)\n",
    "    weight[Constants.PAD] = 0\n",
    "    return nn.CrossEntropyLoss(weight, size_average=False)\n",
    "\n",
    "crit_G = get_criterion(len(EN.vocab))\n",
    "crit_D = nn.BCELoss()\n",
    "\n",
    "if opt.cuda:\n",
    "    G_a.cuda()\n",
    "    G_b.cuda()\n",
    "    D_a.cuda()\n",
    "    D_b.cuda()\n",
    "    crit_G.cuda()\n",
    "    crit_D.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_G = trainers.TransformerTrainer()\n",
    "trainer = trainers.DualGanPGTrainer(\n",
    "    opt,\n",
    "    trainer_G=trainer_G,\n",
    "    trainer_D=trainers.DiscriminatorTrainer())\n",
    "\n",
    "def eval_G(model):\n",
    "    _, val_iter = data.BucketIterator.splits(\n",
    "        (train_lang8, val_lang8), batch_sizes=(opt.batch_size, 128), device=opt.device,\n",
    "        sort_key=lambda x: len(x.src), repeat=False)\n",
    "    trainer_G.evaluate(model, val_iter, crit_G, EN)\n",
    "\n",
    "for epoch in range(10):\n",
    "    logging.info('[Epoch %d]' % epoch)\n",
    "\n",
    "    train_iter = data.BucketIterator(\n",
    "        dataset=train, batch_size=opt.batch_size, device=opt.device,\n",
    "        sort_key=lambda x: len(x.src), repeat=False)\n",
    "    # batch = next(iter(train_iter))\n",
    "    # src_seq = batch.src\n",
    "    # tgt_seq = batch.tgt\n",
    "\n",
    "    trainer.train(\n",
    "        0,\n",
    "        train_iter,\n",
    "        G_a=G_a,\n",
    "        G_b=G_b,\n",
    "        D_a=D_a,\n",
    "        D_b=D_b,\n",
    "        optim_G_a=optim_G_a,\n",
    "        optim_G_b=optim_G_b,\n",
    "        optim_D_a=optim_D_a,\n",
    "        optim_D_b=optim_D_b,\n",
    "        crit_G=crit_G,\n",
    "        crit_D=crit_D,\n",
    "        eval_G=eval_G,\n",
    "        A_FIELD=EN,\n",
    "        B_FIELD=EN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
